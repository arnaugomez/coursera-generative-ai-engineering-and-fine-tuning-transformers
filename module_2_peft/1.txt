<div aria-labelledby="cds-react-aria-51-tab-TRANSCRIPT" id="cds-react-aria-51-panel-TRANSCRIPT" role="tabpanel" class="css-oehwox"><div class="cds-1 css-gr5vn3 cds-2 cds-19"><div class="cds-1 css-arowdh cds-3 cds-grid-item cds-48 cds-73"><div><span data-testid="visually-hidden" class="rc-A11yScreenReaderOnly css-1whdyhf"><h3>Interactive Transcript - Enable basic transcript mode by pressing the escape key</h3></span><div class="rc-TranscriptHighlighter css-79elbk"><p data-testid="visually-hidden" class="rc-A11yScreenReaderOnly css-1whdyhf">You may navigate through the transcript using tab. To save a note for a section of text press ⌘ + S. To expand your selection you may use ⌘ + arrow key. You may contract your selection using shift + ⌘ + arrow key. For screen readers that are incompatible with using arrow keys for shortcuts, you can replace them with the H J K L keys. Some screen readers may require using ⌘ in conjunction with the alt key</p><div data-track="true" data-track-app="open_course_home" data-track-page="focused_lex_video_item" data-track-action="click" data-track-component="interactive_transcript" class="rc-Transcript css-9li235" role="presentation"><div class="cds-1 css-1shylkf cds-2"><div class="cds-1 rc-Paragraph css-1g0t9dn cds-3 cds-grid-item"><button type="button" class="timestamp" aria-labelledby="button-label-1"><span id="button-label-1" class="sr-only"><span>Play video starting at ::7 and follow transcript</span></span>0:07</button><div class="phrases"><div tabindex="0" role="button" data-cue="1" class="rc-Phrase css-13o25cb" data-cue-index="0" aria-label="play video from Welcome to introduction to PEFT, after watching this video you'll be able to"><span class=" css-4s48ix" aria-hidden="true">Welcome to introduction to PEFT, after watching this video you'll be able to </span></div><div tabindex="0" role="button" data-cue="2" class="rc-Phrase css-13o25cb" data-cue-index="1" aria-label="play video from explain the concept of parameter-efficient fine-tuning, or PEFT, and its importance."><span class=" css-4s48ix" aria-hidden="true">explain the concept of parameter-efficient fine-tuning, or PEFT, and its importance. </span></div><div tabindex="0" role="button" data-cue="3" class="rc-Phrase css-13o25cb" data-cue-index="2" aria-label="play video from Describe the types and uses of PEFT methods and"><span class=" css-4s48ix" aria-hidden="true">Describe the types and uses of PEFT methods and </span></div><div tabindex="0" role="button" data-cue="4" class="rc-Phrase css-13o25cb" data-cue-index="3" aria-label="play video from recognize the concept of soft prompts and ranks."><span class=" css-4s48ix" aria-hidden="true">recognize the concept of soft prompts and ranks. </span></div><div tabindex="0" role="button" data-cue="5" class="rc-Phrase css-13o25cb" data-cue-index="4" aria-label="play video from SFT, or supervised fine-tuning, is a method commonly used in machine learning,"><span class=" css-4s48ix" aria-hidden="true">SFT, or supervised fine-tuning, is a method commonly used in machine learning, </span></div><div tabindex="0" role="button" data-cue="6" class="rc-Phrase css-13o25cb" data-cue-index="5" aria-label="play video from especially when working with pretrained models in transfer learning."><span class=" css-4s48ix" aria-hidden="true">especially when working with pretrained models in transfer learning. </span></div><div tabindex="0" role="button" data-cue="7" class="rc-Phrase css-13o25cb" data-cue-index="6" aria-label="play video from This method involves acquiring the knowledge and understanding a model has"><span class=" css-4s48ix" aria-hidden="true">This method involves acquiring the knowledge and understanding a model has </span></div><div tabindex="0" role="button" data-cue="8" class="rc-Phrase css-13o25cb" data-cue-index="7" aria-label="play video from gained from previous training and adapting it to a new task."><span class=" css-4s48ix" aria-hidden="true">gained from previous training and adapting it to a new task. </span></div><div tabindex="0" role="button" data-cue="9" class="rc-Phrase css-13o25cb" data-cue-index="8" aria-label="play video from One of the commonly used methods in supervised fine-tuning,"><span class=" css-4s48ix" aria-hidden="true">One of the commonly used methods in supervised fine-tuning, </span></div><div tabindex="0" role="button" data-cue="10" class="rc-Phrase css-13o25cb" data-cue-index="9" aria-label="play video from full fine-tuning involves updating the learning parameters, layers and"><span class=" css-4s48ix" aria-hidden="true">full fine-tuning involves updating the learning parameters, layers and </span></div><div tabindex="0" role="button" data-cue="11" class="rc-Phrase css-13o25cb" data-cue-index="10" aria-label="play video from neurons of large language models or LLMs."><span class=" css-4s48ix" aria-hidden="true">neurons of large language models or LLMs. </span></div><div tabindex="0" role="button" data-cue="12" class="rc-Phrase css-13o25cb" data-cue-index="11" aria-label="play video from It demands significant computational resources and memory, and"><span class=" css-4s48ix" aria-hidden="true">It demands significant computational resources and memory, and </span></div><div tabindex="0" role="button" data-cue="13" class="rc-Phrase css-13o25cb" data-cue-index="12" aria-label="play video from substantial task-specific labeled data."><span class=" css-4s48ix" aria-hidden="true">substantial task-specific labeled data. </span></div><div tabindex="0" role="button" data-cue="14" class="rc-Phrase css-13o25cb" data-cue-index="13" aria-label="play video from It also has a higher risk of overfitting, is time-consuming, and"><span class=" css-4s48ix" aria-hidden="true">It also has a higher risk of overfitting, is time-consuming, and </span></div><div tabindex="0" role="button" data-cue="15" class="rc-Phrase css-13o25cb" data-cue-index="14" aria-label="play video from involves complex implementation, in addition,"><span class=" css-4s48ix" aria-hidden="true">involves complex implementation, in addition, </span></div><div tabindex="0" role="button" data-cue="16" class="rc-Phrase css-13o25cb" data-cue-index="15" aria-label="play video from one inherent issue with full-fine tuning is catastrophic forgetting."><span class=" css-4s48ix" aria-hidden="true">one inherent issue with full-fine tuning is catastrophic forgetting. </span></div><div tabindex="0" role="button" data-cue="17" class="rc-Phrase css-13o25cb" data-cue-index="16" aria-label="play video from Where the model forgets previously learned information upon being trained with new"><span class=" css-4s48ix" aria-hidden="true">Where the model forgets previously learned information upon being trained with new </span></div><div tabindex="0" role="button" data-cue="18" class="rc-Phrase css-13o25cb" data-cue-index="17" aria-label="play video from data, leading to a loss of valuable pretrained knowledge."><span class=" css-4s48ix" aria-hidden="true">data, leading to a loss of valuable pretrained knowledge. </span></div><div tabindex="0" role="button" data-cue="19" class="rc-Phrase css-13o25cb" data-cue-index="18" aria-label="play video from For this reason, parameter-efficient fine-tuning, or"><span class=" css-4s48ix" aria-hidden="true">For this reason, parameter-efficient fine-tuning, or </span></div><div tabindex="0" role="button" data-cue="20" class="rc-Phrase css-13o25cb" data-cue-index="19" aria-label="play video from PEFT methods have been developed."><span class=" css-4s48ix" aria-hidden="true">PEFT methods have been developed. </span></div><div tabindex="0" role="button" data-cue="21" class="rc-Phrase css-13o25cb" data-cue-index="20" aria-label="play video from PEFT methods reduce the number of trainable parameters that need to be"><span class=" css-4s48ix" aria-hidden="true">PEFT methods reduce the number of trainable parameters that need to be </span></div><div tabindex="0" role="button" data-cue="22" class="rc-Phrase css-13o25cb" data-cue-index="21" aria-label="play video from updated to effectively adapt a large pretrained model to specific downstream"><span class=" css-4s48ix" aria-hidden="true">updated to effectively adapt a large pretrained model to specific downstream </span></div><div tabindex="0" role="button" data-cue="23" class="rc-Phrase css-13o25cb" data-cue-index="22" aria-label="play video from applications."><span class=" css-4s48ix" aria-hidden="true">applications. </span></div><div tabindex="0" role="button" data-cue="24" class="rc-Phrase css-13o25cb" data-cue-index="23" aria-label="play video from In doing so, PEFT significantly decreases the computational resources and"><span class=" css-4s48ix" aria-hidden="true">In doing so, PEFT significantly decreases the computational resources and </span></div><div tabindex="0" role="button" data-cue="25" class="rc-Phrase css-13o25cb" data-cue-index="24" aria-label="play video from memory storage needed to yield an effectively fine-tuned model."><span class=" css-4s48ix" aria-hidden="true">memory storage needed to yield an effectively fine-tuned model. </span></div><div tabindex="0" role="button" data-cue="26" class="rc-Phrase css-13o25cb" data-cue-index="25" aria-label="play video from PEFT methods include selective fine-tuning, additive fine-tuning,"><span class=" css-4s48ix" aria-hidden="true">PEFT methods include selective fine-tuning, additive fine-tuning, </span></div><div tabindex="0" role="button" data-cue="27" class="rc-Phrase css-13o25cb" data-cue-index="26" aria-label="play video from and reparameterization fine-tuning."><span class=" css-4s48ix" aria-hidden="true">and reparameterization fine-tuning. </span></div><div tabindex="0" role="button" data-cue="28" class="rc-Phrase css-13o25cb" data-cue-index="27" aria-label="play video from These methods have often been demonstrated to be more"><span class=" css-4s48ix" aria-hidden="true">These methods have often been demonstrated to be more </span></div><div tabindex="0" role="button" data-cue="29" class="rc-Phrase css-13o25cb" data-cue-index="28" aria-label="play video from stable than full fine-tuning methods particularly for NLP use cases."><span class=" css-4s48ix" aria-hidden="true">stable than full fine-tuning methods particularly for NLP use cases. </span></div><div tabindex="0" role="button" data-cue="30" class="rc-Phrase css-13o25cb" data-cue-index="29" aria-label="play video from Lets learn about these methods one by one, first is selective fine-tuning."><span class=" css-4s48ix" aria-hidden="true">Lets learn about these methods one by one, first is selective fine-tuning. </span></div><div tabindex="0" role="button" data-cue="31" class="rc-Phrase css-13o25cb" data-cue-index="30" aria-label="play video from Full fine-tuning, which involves updating the neural parameters, layers and"><span class=" css-4s48ix" aria-hidden="true">Full fine-tuning, which involves updating the neural parameters, layers and </span></div><div tabindex="0" role="button" data-cue="32" class="rc-Phrase css-13o25cb" data-cue-index="31" aria-label="play video from neurons as shown in red and blue, demands significant computational resources and"><span class=" css-4s48ix" aria-hidden="true">neurons as shown in red and blue, demands significant computational resources and </span></div><div tabindex="0" role="button" data-cue="33" class="rc-Phrase css-13o25cb" data-cue-index="32" aria-label="play video from memory."><span class=" css-4s48ix" aria-hidden="true">memory. </span></div><div tabindex="0" role="button" data-cue="34" class="rc-Phrase css-13o25cb" data-cue-index="33" aria-label="play video from On the contrary, selective fine-tuning which updates only a subset of layers or"><span class=" css-4s48ix" aria-hidden="true">On the contrary, selective fine-tuning which updates only a subset of layers or </span></div><div tabindex="0" role="button" data-cue="35" class="rc-Phrase css-13o25cb" data-cue-index="34" aria-label="play video from parameters works for other networks."><span class=" css-4s48ix" aria-hidden="true">parameters works for other networks. </span></div><div tabindex="0" role="button" data-cue="36" class="rc-Phrase css-13o25cb" data-cue-index="35" aria-label="play video from It is less effective for transformer architectures due to their higher number"><span class=" css-4s48ix" aria-hidden="true">It is less effective for transformer architectures due to their higher number </span></div><div tabindex="0" role="button" data-cue="37" class="rc-Phrase css-13o25cb" data-cue-index="36" aria-label="play video from of parameters and the need for more extensive updates."><span class=" css-4s48ix" aria-hidden="true">of parameters and the need for more extensive updates. </span></div><div tabindex="0" role="button" data-cue="38" class="rc-Phrase css-13o25cb" data-cue-index="37" aria-label="play video from This limitation has led to the development of alternative methods,"><span class=" css-4s48ix" aria-hidden="true">This limitation has led to the development of alternative methods, </span></div><div tabindex="0" role="button" data-cue="39" class="rc-Phrase css-13o25cb" data-cue-index="38" aria-label="play video from one of those methods is additive fine-tuning."><span class=" css-4s48ix" aria-hidden="true">one of those methods is additive fine-tuning. </span></div><div tabindex="0" role="button" data-cue="40" class="rc-Phrase css-13o25cb" data-cue-index="39" aria-label="play video from Instead of modifying the existing pretrained parameters, this method"><span class=" css-4s48ix" aria-hidden="true">Instead of modifying the existing pretrained parameters, this method </span></div><div tabindex="0" role="button" data-cue="41" class="rc-Phrase css-13o25cb" data-cue-index="40" aria-label="play video from involves adding new task-specific layers or components to the pretrained model."><span class=" css-4s48ix" aria-hidden="true">involves adding new task-specific layers or components to the pretrained model. </span></div><div tabindex="0" role="button" data-cue="42" class="rc-Phrase css-13o25cb" data-cue-index="41" aria-label="play video from You can then train these additional layers on task specific data while keeping"><span class=" css-4s48ix" aria-hidden="true">You can then train these additional layers on task specific data while keeping </span></div><div tabindex="0" role="button" data-cue="43" class="rc-Phrase css-13o25cb" data-cue-index="42" aria-label="play video from the pretrained parameters fixed."><span class=" css-4s48ix" aria-hidden="true">the pretrained parameters fixed. </span></div><div tabindex="0" role="button" data-cue="44" class="rc-Phrase css-13o25cb" data-cue-index="43" aria-label="play video from Additive fine-tuning allows for"><span class=" css-4s48ix" aria-hidden="true">Additive fine-tuning allows for </span></div><div tabindex="0" role="button" data-cue="45" class="rc-Phrase css-13o25cb" data-cue-index="44" aria-label="play video from task-specific customization while preserving the pretrained knowledge."><span class=" css-4s48ix" aria-hidden="true">task-specific customization while preserving the pretrained knowledge. </span></div><div tabindex="0" role="button" data-cue="46" class="rc-Phrase css-13o25cb" data-cue-index="45" aria-label="play video from You can inject additional layers anywhere in the model, in transformers,"><span class=" css-4s48ix" aria-hidden="true">You can inject additional layers anywhere in the model, in transformers, </span></div><div tabindex="0" role="button" data-cue="47" class="rc-Phrase css-13o25cb" data-cue-index="46" aria-label="play video from adapters are used for additive fine-tuning."><span class=" css-4s48ix" aria-hidden="true">adapters are used for additive fine-tuning. </span></div><div tabindex="0" role="button" data-cue="48" class="rc-Phrase css-13o25cb" data-cue-index="47" aria-label="play video from They involve adding layers to a pretrained transformer model specifically between"><span class=" css-4s48ix" aria-hidden="true">They involve adding layers to a pretrained transformer model specifically between </span></div><div tabindex="0" role="button" data-cue="49" class="rc-Phrase css-13o25cb" data-cue-index="48" aria-label="play video from the attention blocks shown in green while keeping most of the models weights frozen."><span class=" css-4s48ix" aria-hidden="true">the attention blocks shown in green while keeping most of the models weights frozen. </span></div><div tabindex="0" role="button" data-cue="50" class="rc-Phrase css-13o25cb" data-cue-index="49" aria-label="play video from If you examine the adapter layers, they start with a down projection layer shown"><span class=" css-4s48ix" aria-hidden="true">If you examine the adapter layers, they start with a down projection layer shown </span></div><div tabindex="0" role="button" data-cue="51" class="rc-Phrase css-13o25cb" data-cue-index="50" aria-label="play video from in blue and yellow, which reduces the input dimension."><span class=" css-4s48ix" aria-hidden="true">in blue and yellow, which reduces the input dimension. </span></div><div tabindex="0" role="button" data-cue="52" class="rc-Phrase css-13o25cb" data-cue-index="51" aria-label="play video from This is followed by a non linear transformation and"><span class=" css-4s48ix" aria-hidden="true">This is followed by a non linear transformation and </span></div><div tabindex="0" role="button" data-cue="53" class="rc-Phrase css-13o25cb" data-cue-index="52" aria-label="play video from then an up projection layer, also shown in blue and yellow."><span class=" css-4s48ix" aria-hidden="true">then an up projection layer, also shown in blue and yellow. </span></div><div tabindex="0" role="button" data-cue="54" class="rc-Phrase css-13o25cb" data-cue-index="53" aria-label="play video from Which restores the dimension back to that of the transformer, this design allows you"><span class=" css-4s48ix" aria-hidden="true">Which restores the dimension back to that of the transformer, this design allows you </span></div><div tabindex="0" role="button" data-cue="55" class="rc-Phrase css-13o25cb" data-cue-index="54" aria-label="play video from to use an off the shelf transformer with only the adapters needing to be stored."><span class=" css-4s48ix" aria-hidden="true">to use an off the shelf transformer with only the adapters needing to be stored. </span></div><div tabindex="0" role="button" data-cue="56" class="rc-Phrase css-13o25cb" data-cue-index="55" aria-label="play video from The transformer maintains a general understanding of language,"><span class=" css-4s48ix" aria-hidden="true">The transformer maintains a general understanding of language, </span></div><div tabindex="0" role="button" data-cue="57" class="rc-Phrase css-13o25cb" data-cue-index="56" aria-label="play video from while the adapters store information specific to a particular problem."><span class=" css-4s48ix" aria-hidden="true">while the adapters store information specific to a particular problem. </span></div><div tabindex="0" role="button" data-cue="58" class="rc-Phrase css-13o25cb" data-cue-index="57" aria-label="play video from To train large pretrained language models,"><span class=" css-4s48ix" aria-hidden="true">To train large pretrained language models, </span></div><div tabindex="0" role="button" data-cue="59" class="rc-Phrase css-13o25cb" data-cue-index="58" aria-label="play video from you require a significant amount of time and computational resources."><span class=" css-4s48ix" aria-hidden="true">you require a significant amount of time and computational resources. </span></div><div tabindex="0" role="button" data-cue="60" class="rc-Phrase css-13o25cb" data-cue-index="59" aria-label="play video from As these models increase in size,"><span class=" css-4s48ix" aria-hidden="true">As these models increase in size, </span></div><div tabindex="0" role="button" data-cue="61" class="rc-Phrase css-13o25cb" data-cue-index="60" aria-label="play video from you can leverage soft prompts to improve the training process."><span class=" css-4s48ix" aria-hidden="true">you can leverage soft prompts to improve the training process. </span></div><div tabindex="0" role="button" data-cue="62" class="rc-Phrase css-13o25cb" data-cue-index="61" aria-label="play video from Soft prompts are learnable tensors concatenated with the input embeddings"><span class=" css-4s48ix" aria-hidden="true">Soft prompts are learnable tensors concatenated with the input embeddings </span></div><div tabindex="0" role="button" data-cue="63" class="rc-Phrase css-13o25cb" data-cue-index="62" aria-label="play video from that can be optimized to a dataset."><span class=" css-4s48ix" aria-hidden="true">that can be optimized to a dataset. </span></div><div tabindex="0" role="button" data-cue="64" class="rc-Phrase css-13o25cb" data-cue-index="63" aria-label="play video from Soft prompt methods include prompt tuning, prefix tuning, p-tuning, and"><span class=" css-4s48ix" aria-hidden="true">Soft prompt methods include prompt tuning, prefix tuning, p-tuning, and </span></div><div tabindex="0" role="button" data-cue="65" class="rc-Phrase css-13o25cb" data-cue-index="64" aria-label="play video from multitask prompt tuning."><span class=" css-4s48ix" aria-hidden="true">multitask prompt tuning. </span></div><div tabindex="0" role="button" data-cue="66" class="rc-Phrase css-13o25cb" data-cue-index="65" aria-label="play video from Let's take a closer look at prefix tuning, consider you are training the following"><span class=" css-4s48ix" aria-hidden="true">Let's take a closer look at prefix tuning, consider you are training the following </span></div><div tabindex="0" role="button" data-cue="67" class="rc-Phrase css-13o25cb" data-cue-index="66" aria-label="play video from decoder model from a general chatbot to a medical chatbot."><span class=" css-4s48ix" aria-hidden="true">decoder model from a general chatbot to a medical chatbot. </span></div><div tabindex="0" role="button" data-cue="68" class="rc-Phrase css-13o25cb" data-cue-index="67" aria-label="play video from Instead of training the entire model on the dataset,"><span class=" css-4s48ix" aria-hidden="true">Instead of training the entire model on the dataset, </span></div><div tabindex="0" role="button" data-cue="69" class="rc-Phrase css-13o25cb" data-cue-index="68" aria-label="play video from you can simply append parameter embeddings to the existing embeddings."><span class=" css-4s48ix" aria-hidden="true">you can simply append parameter embeddings to the existing embeddings. </span></div><div tabindex="0" role="button" data-cue="70" class="rc-Phrase css-13o25cb" data-cue-index="69" aria-label="play video from As shown here, the original embeddings are in purple and"><span class=" css-4s48ix" aria-hidden="true">As shown here, the original embeddings are in purple and </span></div><div tabindex="0" role="button" data-cue="71" class="rc-Phrase css-13o25cb" data-cue-index="70" aria-label="play video from the new embeddings are in red."><span class=" css-4s48ix" aria-hidden="true">the new embeddings are in red. </span></div><div tabindex="0" role="button" data-cue="72" class="rc-Phrase css-13o25cb" data-cue-index="71" aria-label="play video from You'll then train the new model by freezing all the parameters except for"><span class=" css-4s48ix" aria-hidden="true">You'll then train the new model by freezing all the parameters except for </span></div><div tabindex="0" role="button" data-cue="73" class="rc-Phrase css-13o25cb" data-cue-index="72" aria-label="play video from the embeddings."><span class=" css-4s48ix" aria-hidden="true">the embeddings. </span></div><div tabindex="0" role="button" data-cue="74" class="rc-Phrase css-13o25cb" data-cue-index="73" aria-label="play video from Now, before learning about the most popular PEFT method,"><span class=" css-4s48ix" aria-hidden="true">Now, before learning about the most popular PEFT method, </span></div><div tabindex="0" role="button" data-cue="75" class="rc-Phrase css-13o25cb" data-cue-index="74" aria-label="play video from the reparameterization-based method lets review the concept of rank."><span class=" css-4s48ix" aria-hidden="true">the reparameterization-based method lets review the concept of rank. </span></div><div tabindex="0" role="button" data-cue="76" class="rc-Phrase css-13o25cb" data-cue-index="75" aria-label="play video from Rank tells you the minimum number of vectors needed to span a space."><span class=" css-4s48ix" aria-hidden="true">Rank tells you the minimum number of vectors needed to span a space. </span></div><div tabindex="0" role="button" data-cue="77" class="rc-Phrase css-13o25cb" data-cue-index="76" aria-label="play video from It is essentially what you commonly think of as a dimension,"><span class=" css-4s48ix" aria-hidden="true">It is essentially what you commonly think of as a dimension, </span></div><div tabindex="0" role="button" data-cue="78" class="rc-Phrase css-13o25cb" data-cue-index="77" aria-label="play video from consider 2 vectors in a 2D space."><span class=" css-4s48ix" aria-hidden="true">consider 2 vectors in a 2D space. </span></div><div tabindex="0" role="button" data-cue="79" class="rc-Phrase css-13o25cb" data-cue-index="78" aria-label="play video from These 2 vectors can reach any point in that space, so the rank is 2,"><span class=" css-4s48ix" aria-hidden="true">These 2 vectors can reach any point in that space, so the rank is 2, </span></div><div tabindex="0" role="button" data-cue="80" class="rc-Phrase css-13o25cb" data-cue-index="79" aria-label="play video from now lets say you extend these vectors into a 3D space."><span class=" css-4s48ix" aria-hidden="true">now lets say you extend these vectors into a 3D space. </span></div><div tabindex="0" role="button" data-cue="81" class="rc-Phrase css-13o25cb" data-cue-index="80" aria-label="play video from Even though these 2 vectors now live in a 3D space,"><span class=" css-4s48ix" aria-hidden="true">Even though these 2 vectors now live in a 3D space, </span></div><div tabindex="0" role="button" data-cue="82" class="rc-Phrase css-13o25cb" data-cue-index="81" aria-label="play video from they can still only span a plane within the space."><span class=" css-4s48ix" aria-hidden="true">they can still only span a plane within the space. </span></div><div tabindex="0" role="button" data-cue="83" class="rc-Phrase css-13o25cb" data-cue-index="82" aria-label="play video from Hence their rank remains two as they can only reach points in the 2D plane,"><span class=" css-4s48ix" aria-hidden="true">Hence their rank remains two as they can only reach points in the 2D plane, </span></div><div tabindex="0" role="button" data-cue="84" class="rc-Phrase css-13o25cb" data-cue-index="83" aria-label="play video from not the entire 3D space."><span class=" css-4s48ix" aria-hidden="true">not the entire 3D space. </span></div><div tabindex="0" role="button" data-cue="85" class="rc-Phrase css-13o25cb" data-cue-index="84" aria-label="play video from In neural networks, the input and output layers have fixed dimensions, however,"><span class=" css-4s48ix" aria-hidden="true">In neural networks, the input and output layers have fixed dimensions, however, </span></div><div tabindex="0" role="button" data-cue="86" class="rc-Phrase css-13o25cb" data-cue-index="85" aria-label="play video from you can use low-rank operations to reduce the number of parameters."><span class=" css-4s48ix" aria-hidden="true">you can use low-rank operations to reduce the number of parameters. </span></div><div tabindex="0" role="button" data-cue="87" class="rc-Phrase css-13o25cb" data-cue-index="86" aria-label="play video from As shown,"><span class=" css-4s48ix" aria-hidden="true">As shown, </span></div><div tabindex="0" role="button" data-cue="88" class="rc-Phrase css-13o25cb" data-cue-index="87" aria-label="play video from you only need 2D to span the space even in a higher dimensional context."><span class=" css-4s48ix" aria-hidden="true">you only need 2D to span the space even in a higher dimensional context. </span></div><div tabindex="0" role="button" data-cue="89" class="rc-Phrase css-13o25cb" data-cue-index="88" aria-label="play video from This reduction in dimensionality can help in making the model more efficient."><span class=" css-4s48ix" aria-hidden="true">This reduction in dimensionality can help in making the model more efficient. </span></div><div tabindex="0" role="button" data-cue="90" class="rc-Phrase css-13o25cb" data-cue-index="89" aria-label="play video from Reparameterization-based methods such as LoRA or low-rank adaptation leverage"><span class=" css-4s48ix" aria-hidden="true">Reparameterization-based methods such as LoRA or low-rank adaptation leverage </span></div><div tabindex="0" role="button" data-cue="91" class="rc-Phrase css-13o25cb" data-cue-index="90" aria-label="play video from the concept of re parametrizing network weights using low-rank transformations."><span class=" css-4s48ix" aria-hidden="true">the concept of re parametrizing network weights using low-rank transformations. </span></div><div tabindex="0" role="button" data-cue="92" class="rc-Phrase css-13o25cb" data-cue-index="91" aria-label="play video from This reduces the number of trainable parameters while still working with high"><span class=" css-4s48ix" aria-hidden="true">This reduces the number of trainable parameters while still working with high </span></div><div tabindex="0" role="button" data-cue="93" class="rc-Phrase css-13o25cb" data-cue-index="92" aria-label="play video from dimensional matrices like the pretrained parameters of the network."><span class=" css-4s48ix" aria-hidden="true">dimensional matrices like the pretrained parameters of the network. </span></div><div tabindex="0" role="button" data-cue="94" class="rc-Phrase css-13o25cb" data-cue-index="93" aria-label="play video from In a typical network shown here, the forward method uses the full network."><span class=" css-4s48ix" aria-hidden="true">In a typical network shown here, the forward method uses the full network. </span></div><div tabindex="0" role="button" data-cue="95" class="rc-Phrase css-13o25cb" data-cue-index="94" aria-label="play video from However, in loRA, additional low-rank layers are added to the original layer as"><span class=" css-4s48ix" aria-hidden="true">However, in loRA, additional low-rank layers are added to the original layer as </span></div><div tabindex="0" role="button" data-cue="96" class="rc-Phrase css-13o25cb" data-cue-index="95" aria-label="play video from shown, reducing the number of parameters needed to represent the weight matrices."><span class=" css-4s48ix" aria-hidden="true">shown, reducing the number of parameters needed to represent the weight matrices. </span></div><div tabindex="0" role="button" data-cue="97" class="rc-Phrase css-13o25cb" data-cue-index="96" aria-label="play video from This reparameterization effectively captures the most important directions in"><span class=" css-4s48ix" aria-hidden="true">This reparameterization effectively captures the most important directions in </span></div><div tabindex="0" role="button" data-cue="98" class="rc-Phrase css-13o25cb" data-cue-index="97" aria-label="play video from the data."><span class=" css-4s48ix" aria-hidden="true">the data. </span></div><div tabindex="0" role="button" data-cue="99" class="rc-Phrase css-13o25cb" data-cue-index="98" aria-label="play video from Maintaining the models performance while significantly reducing"><span class=" css-4s48ix" aria-hidden="true">Maintaining the models performance while significantly reducing </span></div><div tabindex="0" role="button" data-cue="100" class="rc-Phrase css-13o25cb" data-cue-index="99" aria-label="play video from computational costs."><span class=" css-4s48ix" aria-hidden="true">computational costs. </span></div><div tabindex="0" role="button" data-cue="101" class="rc-Phrase css-13o25cb" data-cue-index="100" aria-label="play video from Other popular methods similar to LoRA include quantized low-rank adaptation or"><span class=" css-4s48ix" aria-hidden="true">Other popular methods similar to LoRA include quantized low-rank adaptation or </span></div><div tabindex="0" role="button" data-cue="102" class="rc-Phrase css-13o25cb" data-cue-index="101" aria-label="play video from QLoRA and weight decomposed low-rank adaptation or DoRA."><span class=" css-4s48ix" aria-hidden="true">QLoRA and weight decomposed low-rank adaptation or DoRA. </span></div><div tabindex="0" role="button" data-cue="103" class="rc-Phrase css-13o25cb" data-cue-index="102" aria-label="play video from QLoRA combines low-rank adaptations with quantization,"><span class=" css-4s48ix" aria-hidden="true">QLoRA combines low-rank adaptations with quantization, </span></div><div tabindex="0" role="button" data-cue="104" class="rc-Phrase css-13o25cb" data-cue-index="103" aria-label="play video from reducing the memory footprint and computational requirements of the model."><span class=" css-4s48ix" aria-hidden="true">reducing the memory footprint and computational requirements of the model. </span></div><div tabindex="0" role="button" data-cue="105" class="rc-Phrase css-13o25cb" data-cue-index="104" aria-label="play video from While DoRA adjusts the rank in the low-rank space based on the magnitude"><span class=" css-4s48ix" aria-hidden="true">While DoRA adjusts the rank in the low-rank space based on the magnitude </span></div><div tabindex="0" role="button" data-cue="106" class="rc-Phrase css-13o25cb" data-cue-index="105" aria-label="play video from of the components optimizing the models performance and efficiency."><span class=" css-4s48ix" aria-hidden="true">of the components optimizing the models performance and efficiency. </span></div><div tabindex="0" role="button" data-cue="107" class="rc-Phrase css-13o25cb" data-cue-index="106" aria-label="play video from Lets now recap what you learned in this video, you learned that parameter"><span class=" css-4s48ix" aria-hidden="true">Lets now recap what you learned in this video, you learned that parameter </span></div><div tabindex="0" role="button" data-cue="108" class="rc-Phrase css-13o25cb" data-cue-index="107" aria-label="play video from efficient fine-tuning or PEFT methods reduce the number of trainable parameters."><span class=" css-4s48ix" aria-hidden="true">efficient fine-tuning or PEFT methods reduce the number of trainable parameters. </span></div><div tabindex="0" role="button" data-cue="109" class="rc-Phrase css-13o25cb" data-cue-index="108" aria-label="play video from That need to be updated to effectively adapt a large pretrained model to specific"><span class=" css-4s48ix" aria-hidden="true">That need to be updated to effectively adapt a large pretrained model to specific </span></div><div tabindex="0" role="button" data-cue="110" class="rc-Phrase css-13o25cb" data-cue-index="109" aria-label="play video from downstream applications."><span class=" css-4s48ix" aria-hidden="true">downstream applications. </span></div><div tabindex="0" role="button" data-cue="111" class="rc-Phrase css-13o25cb" data-cue-index="110" aria-label="play video from PEFT methods include selective fine-tuning, additive fine-tuning, and"><span class=" css-4s48ix" aria-hidden="true">PEFT methods include selective fine-tuning, additive fine-tuning, and </span></div><div tabindex="0" role="button" data-cue="112" class="rc-Phrase css-13o25cb" data-cue-index="111" aria-label="play video from reparameterization fine-tuning."><span class=" css-4s48ix" aria-hidden="true">reparameterization fine-tuning. </span></div><div tabindex="0" role="button" data-cue="113" class="rc-Phrase css-13o25cb" data-cue-index="112" aria-label="play video from Selective fine-tuning updates only a subset of layers or"><span class=" css-4s48ix" aria-hidden="true">Selective fine-tuning updates only a subset of layers or </span></div><div tabindex="0" role="button" data-cue="114" class="rc-Phrase css-13o25cb" data-cue-index="113" aria-label="play video from parameters that work for other networks."><span class=" css-4s48ix" aria-hidden="true">parameters that work for other networks. </span></div><div tabindex="0" role="button" data-cue="115" class="rc-Phrase css-13o25cb" data-cue-index="114" aria-label="play video from It is less effective for transformer architectures due to their higher number"><span class=" css-4s48ix" aria-hidden="true">It is less effective for transformer architectures due to their higher number </span></div><div tabindex="0" role="button" data-cue="116" class="rc-Phrase css-13o25cb" data-cue-index="115" aria-label="play video from of parameters and the need for more extensive updates."><span class=" css-4s48ix" aria-hidden="true">of parameters and the need for more extensive updates. </span></div><div tabindex="0" role="button" data-cue="117" class="rc-Phrase css-13o25cb" data-cue-index="116" aria-label="play video from Additive fine-tuning involves adding task-specific layers or components to"><span class=" css-4s48ix" aria-hidden="true">Additive fine-tuning involves adding task-specific layers or components to </span></div><div tabindex="0" role="button" data-cue="118" class="rc-Phrase css-13o25cb" data-cue-index="117" aria-label="play video from the pretrained model instead of modifying the existing pretrained parameters."><span class=" css-4s48ix" aria-hidden="true">the pretrained model instead of modifying the existing pretrained parameters. </span></div><div tabindex="0" role="button" data-cue="119" class="rc-Phrase css-13o25cb" data-cue-index="118" aria-label="play video from Adapters are used for additive fine-tuning and"><span class=" css-4s48ix" aria-hidden="true">Adapters are used for additive fine-tuning and </span></div><div tabindex="0" role="button" data-cue="120" class="rc-Phrase css-13o25cb" data-cue-index="119" aria-label="play video from involve adding layers to a pre trained transformer model, specifically between"><span class=" css-4s48ix" aria-hidden="true">involve adding layers to a pre trained transformer model, specifically between </span></div><div tabindex="0" role="button" data-cue="121" class="rc-Phrase css-13o25cb" data-cue-index="120" aria-label="play video from the attention blocks while keeping most of the models weights frozen."><span class=" css-4s48ix" aria-hidden="true">the attention blocks while keeping most of the models weights frozen. </span></div><div tabindex="0" role="button" data-cue="122" class="rc-Phrase css-13o25cb" data-cue-index="121" aria-label="play video from Soft prompts are learnable tensors concatenated with"><span class=" css-4s48ix" aria-hidden="true">Soft prompts are learnable tensors concatenated with </span></div><div tabindex="0" role="button" data-cue="123" class="rc-Phrase css-13o25cb" data-cue-index="122" aria-label="play video from the input embeddings that can be optimized to a dataset."><span class=" css-4s48ix" aria-hidden="true">the input embeddings that can be optimized to a dataset. </span></div><div tabindex="0" role="button" data-cue="124" class="rc-Phrase css-13o25cb" data-cue-index="123" aria-label="play video from Rank tells you the minimum number of vectors needed to span a space."><span class=" css-4s48ix" aria-hidden="true">Rank tells you the minimum number of vectors needed to span a space. </span></div><div tabindex="0" role="button" data-cue="125" class="rc-Phrase css-13o25cb" data-cue-index="124" aria-label="play video from Reparameterization-based methods leverage the concept of reparametrizing network"><span class=" css-4s48ix" aria-hidden="true">Reparameterization-based methods leverage the concept of reparametrizing network </span></div><div tabindex="0" role="button" data-cue="126" class="rc-Phrase css-13o25cb" data-cue-index="125" aria-label="play video from weights using low-rank transformations."><span class=" css-4s48ix" aria-hidden="true">weights using low-rank transformations. </span></div><div tabindex="0" role="button" data-cue="127" class="rc-Phrase css-13o25cb" data-cue-index="126" aria-label="play video from This reduces the number of trainable parameters while still working with high"><span class=" css-4s48ix" aria-hidden="true">This reduces the number of trainable parameters while still working with high </span></div><div tabindex="0" role="button" data-cue="128" class="rc-Phrase css-13o25cb" data-cue-index="127" aria-label="play video from dimensional matrices like the pretrained parameters of the network."><span class=" css-4s48ix" aria-hidden="true">dimensional matrices like the pretrained parameters of the network. </span></div></div></div></div></div></div></div></div><div class="cds-1 css-hcqebr cds-3 cds-grid-item cds-48 cds-66"><div class="css-1xyaw91" data-testid="silent-select-field"><div class="cds-234 cds-219 cds-input-root cds-input-onLight cds-silentSelect-input css-1mhpuva" data-testid="track-chooser-select"><div class="cds-263 cds-264 cds-select-select cds-267 cds-245 cds-229 cds-input-input" tabindex="0" role="button" aria-expanded="false" aria-haspopup="listbox" aria-labelledby="cds-react-aria-60-label cds-react-aria-60-value" id="cds-react-aria-60"><span class="cds-silentSelect-filled css-4s48ix"><span class="cds-silentSelect-label css-1rlln5c" id="cds-react-aria-60-label">Transcript language: </span><span id="cds-react-aria-60-value">English</span></span></div><input aria-hidden="true" tabindex="-1" class="cds-273" value="en"><svg aria-hidden="true" fill="none" focusable="false" height="20" viewBox="0 0 20 20" width="20" class="cds-269 cds-select-icon css-1u8qly9" data-testid="chevron-down-icon" id="cds-react-aria-65"><path fill-rule="evenodd" clip-rule="evenodd" d="M10 14.293L1.354 5.646l-.708.708L10 15.707l9.354-9.353-.707-.708L10 14.293z" fill="currentColor"></path></svg><fieldset aria-hidden="true" class="cds-259 cds-228 cds-input-notchedOutline" style="padding-left: 8px;"><legend class="cds-260" style="width: 0.01px;"><span>​</span></legend></fieldset></div></div></div></div></div>