# Introduction to Transformers and Parameter-Efficient Fine-Tuning

## Course Overview

Welcome to this comprehensive course on **transformers and model frameworks** such as **PyTorch** and **Hugging Face**. This course is designed to equip you with the skills to optimize **large language models (LLMs)** and fine-tune **generative AI models**.

### Key Topics Covered:

- **Transformers and Model Frameworks**: Explore the fundamental concepts and practical applications.
- **Parameter-Efficient Fine-Tuning (PEFT)**: Learn methods to efficiently fine-tune models without extensive computational resources.
- **Low-Rank Adaptation (LoRA) and Quantized Low-Rank Adaptation (QLoRA)**: Understand and apply these techniques to enhance model performance.
- **Hands-On Practice**: Engage in practical labs involving loading, pretraining, fine-tuning, and applying models using **Hugging Face** and **PyTorch**.

### Prerequisites

To get the most out of this course, you should have a basic understanding of:

- Python programming
- PyTorch framework
- Neural networks

This course is suitable for professionals aiming to advance their careers in AI engineering, focusing on training, developing, fine-tuning, and deploying LLMs. It is ideal for data scientists and machine learning engineers with foundational Python knowledge.

## Generative AI for Data Scientists Specialization

This course is part of a broader specialization designed to enhance your expertise in generative AI. The specialization includes:

1. **Generative AI: Introduction and Applications**
2. **Generative AI: Prompt Engineering Basics**
3. **Generative AI: Elevate Your Data Science Career**

### Generative AI Engineering Specialization

- **Course 1**: Generative AI and LLMs: Architecture and Data Preparation
- **Course 2**: Generative AI Foundational Models for NLP & Language Understanding
- **Course 3**: Generative AI Language Modeling with Transformers

## Course Objectives

By the end of this course, you will be able to:

- Explore and use transformers, language model frameworks, and platforms like **LangChain** and **Hugging Face**.
- Demonstrate loading models, making inferences, and fine-tuning models using **PyTorch** and **Hugging Face**.
- Describe **PEFT** concepts and explain adaptors such as **LoRA** and **QLoRA**.

## Course Outline

This course consists of one comprehensive module. To achieve your learning goals, dedicate consistent hours each week to complete the course successfully. Engage with all videos, readings, and activities to solidify your knowledge.

### Module 1: Transformers and Fine-Tuning

- Overview of Hugging Face and PyTorch frameworks in AI development.
- Use of pretrained transformer models.
- Fine-tuning models with Hugging Face and PyTorch.
- Preparing datasets, model definition, and final layer fine-tuning.
- Hands-on lab: Training a base model and pre-training LLMs with Hugging Face and PyTorch.

### Module 2: Parameter Efficient Fine-Tuning (PEFT)

- Insights into PEFT, its importance, types, and methods.
- Exploration of soft prompts and adaptors like LoRA and QLoRA.
- Understanding LoRA's reduction of trainable parameters using pretrained models.
- Unique quantization techniques and methods of QLoRA.
- Hands-on lab: Fine-tuning PEFT adaptors LoRA and QLoRA using PyTorch and Hugging Face.

## Tools/Software Used

- Access course materials on any web-enabled device, including tablets and mobile phones.
- A modern web browser is required to complete the course.
- Access to a cloud-based environment for labs.
- Recommended platforms include **Hugging Face** and **watsonx.ai**.

Congratulations on taking this step towards enhancing your knowledge and advancing your career in AI. Enjoy your learning journey!