# Introduction to Fine Tuning with Transformers

Welcome to this course about fine-tuning with transformers. This course is driven by key trends in **AI and Natural Language Processing (NLP)**, highlighting fine-tuning with transformers as a cornerstone of AI strategies across various industries.

## Key Topics and Learning Objectives

- **AI and NLP Trends**: Understand how fine-tuning with transformers is becoming essential in AI strategies.
- **AI Application in Industries**: Learn how companies utilize AI in specialized contexts as large language models (LLMs) evolve.
- **AI Engineering Concepts**: Work with in-demand LLMs to build job-ready skills for advancing your AI career.

## Course Focus

- **Encoder Models**: The course will primarily focus on encoder models for simplicity, but the methods can also be applied to decoder models.
- **Target Audience**: Suitable for data scientists, machine learning engineers, deep learning engineers, AI engineers, and developers aspiring to excel with LLMs.

## Prerequisites

- **Basic Knowledge**: Python and PyTorch fundamentals, awareness of transformers fine-tuning, and familiarity with loading models are advantageous.

## Course Outcomes

- **Generative AI Engineering**: Post-course, you'll be able to apply skills in working with transformer-based LLMs.
- **Pretrained Transformers**: Learn to use pretrained transformers for language tasks and fine-tune them for specific applications.
- **Parameter Efficient Fine Tuning (PEFT)**: Gain insights into PEFT using low-rank adaptation (LoRA) and quantize low-rank adaptation (QLoRA).

## Course Structure

1. **Transformers and Language Models**:
   - Understand generative models and fine-tuning techniques.
   - Review advanced training methods and compare frameworks like HuggingFace and PyTorch.

2. **Model Loading and Training**:
   - Learn how to load a model and perform inference and training or pretraining using HuggingFace.
   - Understand the importance of fine-tuning models using HuggingFace within PyTorch.

3. **PEFT Adapters**:
   - Explore adapters such as LoRA and QLoRA.
   - Gain insights into soft prompts and rank.

4. **Model Quantization**:
   - Define model quantization using NLP and its unique methods.

## Course Components

- **Labs**: Hands-on labs using Jupyter labs to reinforce learning and practice concepts and technology.
- **Videos and Readings**: Short, focused videos and detailed text readings to provide comprehensive understanding.
- **Quizzes**: Practice and graded quizzes to apply learned concepts and assess knowledge.
- **Discussion Forums**: Engage with peers and seek help from course staff.

## Getting Started

Prepare to embark on this exciting journey in AI and transformer technologies. Good luck!