"Which transformer models are mentioned as having advanced NLP?", "BERT, Llama, GPT"
"What type of architecture do transformer models use?", "Attention-based"
"Why is pre-training important for transformer models?", "It allows learning rich language representations for various NLP tasks."
"What are the challenges of training large language models (LLMs)?", "Computational expense, substantial training data, time-consuming, infrastructure costs"
"What is the primary goal of fine-tuning a pre-trained model?", "To adapt the model to specific tasks or domains using domain-specific data"
"List one benefit of fine-tuning.", "Efficiency - Saves time and computational resources"
"What is a pitfall to avoid during fine-tuning?", "Overfitting"
"What approach to fine-tuning predicts missing words in large datasets?", "Self-Supervised Fine-Tuning"
"What is RLHF in the context of fine-tuning?", "Reinforcement Learning from Human Feedback"
"What does Direct Preference Optimization focus on?", "Aligning outputs with human preferences"
"What is the difference between full fine-tuning and parameter-efficient fine-tuning?", "Full fine-tuning tunes all model parameters, while PEFT fine-tunes large models without modifying most parameters."
"Why is fine-tuning considered more resource-efficient than training LLMs from scratch?", "It enhances model performance by leveraging pre-training, reducing the need for extensive computational resources."
"What is one emerging technique that focuses on aligning models with human preferences?", "Direct Preference Optimization"